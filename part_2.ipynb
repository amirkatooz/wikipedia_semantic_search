{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "In this part I will use Latent Semantic Analysis to search the downloaded articles. My code, given a search term, will find the top 5 related articles to the search query.\n",
    "\n",
    "I have gathered around 10,000 wikipedia articles in 8 different categories. These categories are:\n",
    "- machine learning\n",
    "- business software\n",
    "- association football\n",
    "- engineering\n",
    "- quantum mechanics\n",
    "- evolution\n",
    "- music\n",
    "- econimics\n",
    "\n",
    "Let's load the data from postgreSQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib.database_manager import query_to_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles_df = query_to_dataframe('SELECT * FROM articles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing documents\n",
    "\n",
    "I have used `TfidfVectorizer` to vectorize the articles content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df=.005, max_df=.9, ngram_range=(1, 3), stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "document_term_matrix = tfidf_vectorizer.fit_transform(articles_df['article_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "document_term_matrix_df = pd.DataFrame(document_term_matrix.toarray(), \n",
    "                                       columns=tfidf_vectorizer.get_feature_names(),\n",
    "                                       index=articles_df['article_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10496, 9066)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_term_matrix_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pickle this vectorizer for future use (in part 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tfidf_vectorizer, open('vectorizer.py', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute SVD of document term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVD = TruncatedSVD(n_components=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd_matrix = SVD.fit_transform(document_term_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_semantic_analysis = pd.DataFrame(svd_matrix,\n",
    "                                        index=document_term_matrix_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10496, 350)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_semantic_analysis.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pickle the `latent_semantic_analysis` dataframe and the dimensionality reduction model as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(SVD, open('SVD.py', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_semantic_analysis.to_pickle('lsa_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search the articles\n",
    "\n",
    "The code below works for any number of search terms. There is a list containing all the search terms and the code returns 5 top related articles to each one of the search terms. To find the related articles I used cosine similarity as well as nearest neighbors approach.\n",
    "\n",
    "First we need to vectorize and reduce the dimensionality of the search terms using our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_terms = ['principal component analysis',\n",
    "                'schrodinger equation',\n",
    "                'penalty kick',\n",
    "                'soil structure interaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_terms_matrix = tfidf_vectorizer.transform(search_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_terms_svd_matrix = SVD.transform(search_terms_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "co_sim_df = pd.DataFrame(cosine_similarity(latent_semantic_analysis, search_terms_svd_matrix),\n",
    "                         index=articles_df['article_title'],\n",
    "                         columns=search_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_related_articles_list = [co_sim_df[search_term].sort_values(ascending=False)[:5] for search_term in search_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 related articles to \"principal component analysis\" are:\n",
      "\n",
      "Principal geodesic analysis\n",
      "Correspondence analysis\n",
      "Tucker decomposition\n",
      "Multiple correspondence analysis\n",
      "Multilinear principal component analysis\n",
      "\n",
      "\n",
      "top 5 related articles to \"schrodinger equation\" are:\n",
      "\n",
      "Schrödinger–Newton equation\n",
      "Relativistic wave equations\n",
      "Heisenberg-Langevin equation\n",
      "Logarithmic Schrödinger equation\n",
      "Soliton\n",
      "\n",
      "\n",
      "top 5 related articles to \"penalty kick\" are:\n",
      "\n",
      "Indirect free kick\n",
      "Penalty kick (association football)\n",
      "Direct free kick\n",
      "Penalty area\n",
      "Bicycle kick\n",
      "\n",
      "\n",
      "top 5 related articles to \"soil structure interaction\" are:\n",
      "\n",
      "Fender pier\n",
      "Bistable structure\n",
      "Gravity-based structure\n",
      "Active structure\n",
      "Prestressed structure\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, search_term in enumerate(search_terms):\n",
    "    print('top 5 related articles to \"{}\" are:'.format(search_term))\n",
    "    print('')\n",
    "    for j in range(5):\n",
    "        print(top_related_articles_list[i].index[j])\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = NearestNeighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(svd_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similar_article_indices = nn.kneighbors(search_terms_svd_matrix, n_neighbors=5)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2342, 2290, 2324, 1746, 1747],\n",
       "       [5496, 5722, 5570, 5454, 6283],\n",
       "       [2920, 3015, 2922, 2988, 2913],\n",
       "       [5046, 4933, 4346, 9450, 4198]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_article_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 related articles to \"principal component analysis\" are:\n",
      "\n",
      "Principal geodesic analysis\n",
      "Correspondence analysis\n",
      "Tucker decomposition\n",
      "Multilinear principal component analysis\n",
      "Multilinear subspace learning\n",
      "\n",
      "\n",
      "top 5 related articles to \"schrodinger equation\" are:\n",
      "\n",
      "Heisenberg-Langevin equation\n",
      "Schrödinger group\n",
      "Non-Hermitian quantum mechanics\n",
      "Faddeev equations\n",
      "Diffuson\n",
      "\n",
      "\n",
      "top 5 related articles to \"penalty kick\" are:\n",
      "\n",
      "Penalty area\n",
      "Sliding tackle\n",
      "Penalty kick (association football)\n",
      "Bicycle kick\n",
      "Indirect free kick\n",
      "\n",
      "\n",
      "top 5 related articles to \"soil structure interaction\" are:\n",
      "\n",
      "Fender pier\n",
      "Bistable structure\n",
      "Strongback (girder)\n",
      "Serial homology\n",
      "Centring\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, search_term in enumerate(search_terms):\n",
    "    print('top 5 related articles to \"{}\" are:'.format(search_term))\n",
    "    print('')\n",
    "    for j in range(5):\n",
    "        print(articles_df.iloc[similar_article_indices[i],:][['article_title']].values[j][0])\n",
    "    print('')\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
